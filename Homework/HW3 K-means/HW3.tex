%%%%%%%%%全局设置%%%%%%%%%
\documentclass[a4paper,11pt]{article}
\usepackage{fancyhdr}
\usepackage{amsmath,amsfonts,amssymb,graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{indentfirst}
\usepackage{epstopdf}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{threeparttable}
\usepackage[colorlinks,linkcolor=black,anchorcolor=black,citecolor=black]{hyperref}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\usepackage{algorithm}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm  
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm  

\lstset{
	numbers=left,
    numberstyle=\tiny,
	basicstyle=\small\ttfamily,
	stringstyle=\color{purple},
 	keywordstyle=\color{blue}\bfseries,
	commentstyle=\color{olive},
	frame=shadowbox,
	%framerule=0pt,
	%backgroundcolor=\color{pink},
	rulesepcolor=\color{red!20!green!20!blue!20},
	%rulesepcolor=\color{brown}
	%xleftmargin=2em,xrightmargin=2em,aboveskip=1em
	escapeinside=``, 
    basicstyle=\tiny
}
%%%%%%%%%%%%%重定义中文环境名%%%%%%%
\renewcommand{\lstlistingname}{程序}

%%%%%%%%%%%%风格设置%%%%%%%%%%%%%%%
\addtolength{\topmargin}{-54pt}
\setlength{\oddsidemargin}{-0.5cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\textwidth}{17.00cm}
\setlength{\textheight}{24.50cm}
\renewcommand{\baselinestretch}{1.1}
\parindent 22pt

%%%%%%%%%%%%%%正文%%%%%%%%%%%%%%%%
\title{\Large\textbf{Homework3: Clustering}}
\author{Mingyi Xue\footnote{GSP student from Nanjing University}}

\begin{document}
\date{\today}
\maketitle
\section{Problem 1. K-means clustering}
\subsection{Algorithm}
k-means objective,\\
\begin{equation}
J = \sum_{k=1}^{K}\sum_{\bm{x}_{n}\in C_{k}}^{}\|\bm{x}_{n}-\bm{m}_{k}\|_{2}^{2}
\end{equation}
\par
Firstly, initial centers are randomly selected and stored in a list. Secondly, in each iteration, we compute distances from the current point to each center in the list. The shortest distance will be added directly to objective described above and the index of current point will be appended to the corresponding value list in a cluster dictionary. Finally, the list of centers will be updated with infomation of cluster dictionary.\par
\begin{table}[H]
	\begin{center}
		\caption{Data Structure}
		\begin{tabular}{ccc}
			\toprule[2pt] 
			name & structure&element\\
			\hline
			X      &numpy.ndarray&shape of (N,m)\\
			centers&list         &numpy.ndarray, shape of (1,m)\\
			dit    &dictionary   &key : index of centers, value : list of row indices in X\\
			J      &list         &real number\\
			time$\_$lst&list      &time.time()\\
			
			\bottomrule[2pt]
		\end{tabular} 
	\end{center}
\end{table}
\begin{table}[H]
	\begin{center}
		\caption{Default parameters}
		\begin{tabular}{cc}
			\toprule[2pt] 
			name & value\\
			\hline
			$\#$ of centers&10\\
			$\#$ of iteration&40\\
			\bottomrule[2pt]
		\end{tabular} 
	\end{center}
\end{table}
\subsection{Result}
\begin{table}[H]
	\begin{center}
		\caption{Result of dense dataset}
		\begin{tabular}{cc}
			\toprule[2pt] 
			iteration & objective function\\
			\hline
			10		  &	55737.842681\\
			20		  &	55685.979060\\
			30		  &	55685.808653\\
			40		  &	55685.808653\\
			\hline
			total time($sec$)&345.9897\\
			\bottomrule[2pt]
		\end{tabular} 
	\end{center}
\end{table}
\begin{figure}[H]
	\centering
		\centering
		\includegraphics[width=0.6\textwidth]{dense.png}
	\caption{Reduction in objective function}
\end{figure}
\subsection{Conclusion}
I find that the program have converged within 40 iterations since the objective of the $40^{th}$ iteration is the same as that of the $30^{th}$ iteration. Besides, the derivative of reduction in objective is always negative and monotonically increasing.\par
\section{Problem 2. K-means for sparse data}
\subsection{Algorithm}
Almost the same with Problem 1, except that dataset X is a scipy.sparse matrix and that centers are initialized with the first 10 rows in the dataset to avoid extra computation.\par
\begin{table}[H]
\begin{center}
	\caption{Default parameters}
	\begin{tabular}{cc}
		\toprule[2pt] 
		name & value\\
		\hline
		$\#$ of centers&10\\
		$\#$ of iteration&40\\
		\bottomrule[2pt]
	\end{tabular} 
\end{center}
\end{table}
\subsection{Result}
\begin{table}[H]
	\begin{center}
		\caption{Result of sparse dataset}
		\begin{tabular}{cc}
			\toprule[2pt] 
			iteration & objective function\\
			\hline
			10		  &	201.334622\\
			20		  &	169.798514\\
			30		  &	163.539468\\
			40		  &	162.579801\\
			\hline
			approximate time/iter($sec$)&240\\
			\bottomrule[2pt]
		\end{tabular} 
	\end{center}
\end{table}
\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.0\textwidth]{40.png}
		\subcaption{40 iterations}
	\end{subfigure}
	\quad
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.0\textwidth]{80.png}
		\subcaption{80 iterations}
	\end{subfigure}	
	\caption{Reduction in objective function}
\end{figure}
\subsection{Conclusion}
I find that the program have not converged yet at the $40^{th}$ iteration since the objective of the $40^{th}$ iteration does not equal that of the $30^{th}$ iteration, though quite close. Besides, the derivative of reduction in objective is always negative and monotonically increasing.
\end{document}
