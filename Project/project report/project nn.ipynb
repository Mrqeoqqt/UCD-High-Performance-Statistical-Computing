{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = 'C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis = 0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 1. 0. 0. 1.]\n",
      " [1. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## function test\n",
    "labels = np.array([1,0,1,1,0])\n",
    "one_hot = one_hot_matrix(labels, C = 2)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 17987\n",
      "number of test examples = 7710\n",
      "X_train shape: (116, 17987)\n",
      "Y_train shape: (2, 17987)\n",
      "X_test shape: (116, 7710)\n",
      "Y_test shape: (2, 7710)\n"
     ]
    }
   ],
   "source": [
    "# input file path\n",
    "filename = r'D:\\wkspacePY\\STA 141C\\data\\processed.csv'\n",
    "# load and split data\n",
    "df = pd.read_csv(filename, index_col='shot_id')\n",
    "# training set\n",
    "# X_train: training matrix\n",
    "# Y_train: true label of training matrix\n",
    "# test set\n",
    "# X_test: test matrix\n",
    "# Y_test: true label of test matrix\n",
    "Y = df['shot_made_flag']\n",
    "X = df.drop(['shot_made_flag'], axis=1)\n",
    "Y = Y.as_matrix()\n",
    "X = X.as_matrix()\n",
    "# max_X = np.array([np.linalg.norm(X[:, i]) for i in range(X.shape[1])]).reshape(1, X.shape[1])\n",
    "max_X = np.array([np.max(X[:, i]) for i in range(X.shape[1])]).reshape(1, X.shape[1])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "# Normalize\n",
    "X_train /= max_X\n",
    "X_test /= max_X\n",
    "# Transpose\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y_test.T\n",
    "# convert to one_hot\n",
    "Y_train = one_hot_matrix(Y_train, C = 2)\n",
    "Y_test = one_hot_matrix(Y_test, C = 2)\n",
    "# print info\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y,None])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(4, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(2, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## function test\n",
    "tf.reset_default_graph()\n",
    "X, Y = create_placeholders(X_train.shape[0], Y_train.shape[0])\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(nn):\n",
    "    \"\"\"\n",
    "    layer = len(nn)-1\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [n1, n0]\n",
    "                        b1 : [n1, 1]\n",
    "                        W2 : [n2, n1]\n",
    "                        b2 : [n2, 1]\n",
    "                        ...\n",
    "                        W_layer : [n(layer), n(layer-1)]\n",
    "                        b_layer : [n(layer), 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, ...\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    for i in range(len(nn)-1):\n",
    "        parameters['W' + str(i+1)] = tf.get_variable('W'+str(i+1), [nn[i+1], nn[i]], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "        parameters['b' + str(i+1)] = tf.get_variable('b' + str(i+1), [nn[i+1],1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': <tf.Variable 'W1:0' shape=(25, 4) dtype=float32_ref>, 'b1': <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>, 'W2': <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>, 'b2': <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>, 'W3': <tf.Variable 'W3:0' shape=(2, 12) dtype=float32_ref>, 'b3': <tf.Variable 'b3:0' shape=(2, 1) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "## function test\n",
    "tf.reset_default_graph()\n",
    "neural_num = [X_train.shape[0], 25, 12, 2]\n",
    "parameters = {}\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(neural_num)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", ...\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns: \n",
    "    Z(len(parameters)/2) -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    length = int(len(parameters)/2)\n",
    "    Z = tf.add(tf.matmul(parameters['W1'], X),parameters['b1'])\n",
    "    A = tf.nn.relu(Z)  \n",
    "    for i in range(2, length):\n",
    "        Z = tf.add(tf.matmul(parameters['W'+str(i)], A),parameters['b'+str(i)])\n",
    "        A = tf.nn.relu(Z)  \n",
    "    Z = tf.add(tf.matmul(parameters['W'+str(length)], A),parameters['b'+str(length)])\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 4 and 116 for 'MatMul' (op: 'MatMul') with input shapes: [25,4], [116,?].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 4 and 116 for 'MatMul' (op: 'MatMul') with input shapes: [25,4], [116,?].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d4a19a541047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m116\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneural_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mZ3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Z_3 = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-b0c6297aaec6>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \"\"\"\n\u001b[0;32m     13\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2122\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4276\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4277\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4278\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4279\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4280\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 4 and 116 for 'MatMul' (op: 'MatMul') with input shapes: [25,4], [116,?]."
     ]
    }
   ],
   "source": [
    "## function test\n",
    "tf.reset_default_graph()\n",
    "neural_num = [X_train.shape[0], 25, 12, 2]\n",
    "parameters = {}\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(116, 1)\n",
    "    parameters = initialize_parameters(neural_num)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z_3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z_end, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z_end -- output of forward propagation (output of the last LINEAR unit), of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z_end\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z_end)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-816983b1e3e6>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## function test\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(116, 1)\n",
    "    parameters = initialize_parameters(neural_num)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarded\n",
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "    tf.set_random_seed(seed)\n",
    "    start = 0\n",
    "    interval = minibatch_size\n",
    "    data = np.vstack((Y_train, X_train))\n",
    "    np.random.shuffle(data)\n",
    "    end = start + interval\n",
    "    train_data = []\n",
    "    for i in range(minibatch_size):\n",
    "        if start >= X_train.shape[1]:\n",
    "            break\n",
    "        if end < X_train.shape[1]:\n",
    "            y = data[0:Y_train.shape[0], start:end]\n",
    "            x = data[Y_train.shape[0]:, start:end]\n",
    "        else:\n",
    "            y = data[0:Y_train.shape[0], start:]\n",
    "            x = data[Y_train.shape[0]:, start:]\n",
    "        train_data.append((x,y))\n",
    "        start = end\n",
    "        end = start + interval\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 20557)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## function test\n",
    "tf.reset_default_graph()\n",
    "train_data = random_mini_batches(X_train, Y_train, X_train.shape[1], 2)\n",
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, nn, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, print_cost = True, figname = 'c:/', period = 2000):\n",
    "    \"\"\"\n",
    "    Implements a len(nn)-1 layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->...->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set\n",
    "    Y_train -- test set\n",
    "    X_test -- training set\n",
    "    Y_test -- test set\n",
    "    nn -- input layer + number of neurals in each layer\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    # seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(nn)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z_end = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z_end, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:  \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            if epoch%period == 0:\n",
    "                learning_rate *= 0.1\n",
    "                optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "            _ , tmp_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "            epoch_cost = tmp_cost\n",
    "            \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.savefig(figname)\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(Z_end), tf.argmax(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.734075\n",
      "Cost after epoch 100: 0.680884\n",
      "Cost after epoch 200: 0.674853\n",
      "Cost after epoch 300: 0.667094\n",
      "Cost after epoch 400: 0.659555\n",
      "Cost after epoch 500: 0.655167\n",
      "Cost after epoch 600: 0.653536\n",
      "Cost after epoch 700: 0.652881\n",
      "Cost after epoch 800: 0.652513\n",
      "Cost after epoch 900: 0.652225\n",
      "Cost after epoch 1000: 0.651949\n",
      "Cost after epoch 1100: 0.651721\n",
      "Cost after epoch 1200: 0.651536\n",
      "Cost after epoch 1300: 0.651379\n",
      "Cost after epoch 1400: 0.651276\n",
      "Cost after epoch 1500: 0.651190\n",
      "Cost after epoch 1600: 0.651112\n",
      "Cost after epoch 1700: 0.651040\n",
      "Cost after epoch 1800: 0.650970\n",
      "Cost after epoch 1900: 0.650910\n",
      "Cost after epoch 2000: 0.650855\n",
      "Cost after epoch 2100: 0.650803\n",
      "Cost after epoch 2200: 0.650759\n",
      "Cost after epoch 2300: 0.650719\n",
      "Cost after epoch 2400: 0.650684\n",
      "Cost after epoch 2500: 0.650650\n",
      "Cost after epoch 2600: 0.650618\n",
      "Cost after epoch 2700: 0.650590\n",
      "Cost after epoch 2800: 0.650562\n",
      "Cost after epoch 2900: 0.650537\n",
      "Cost after epoch 3000: 0.650513\n",
      "Cost after epoch 3100: 0.650488\n",
      "Cost after epoch 3200: 0.650467\n",
      "Cost after epoch 3300: 0.650446\n",
      "Cost after epoch 3400: 0.650424\n",
      "Cost after epoch 3500: 0.650402\n",
      "Cost after epoch 3600: 0.650373\n",
      "Cost after epoch 3700: 0.650343\n",
      "Cost after epoch 3800: 0.650322\n",
      "Cost after epoch 3900: 0.650307\n",
      "Cost after epoch 4000: 0.650291\n",
      "Cost after epoch 4100: 0.650276\n",
      "Cost after epoch 4200: 0.650262\n",
      "Cost after epoch 4300: 0.650248\n",
      "Cost after epoch 4400: 0.650235\n",
      "Cost after epoch 4500: 0.650221\n",
      "Cost after epoch 4600: 0.650209\n",
      "Cost after epoch 4700: 0.650197\n",
      "Cost after epoch 4800: 0.650184\n",
      "Cost after epoch 4900: 0.650172\n",
      "Cost after epoch 5000: 0.650160\n",
      "Cost after epoch 5100: 0.650159\n",
      "Cost after epoch 5200: 0.650158\n",
      "Cost after epoch 5300: 0.650157\n",
      "Cost after epoch 5400: 0.650155\n",
      "Cost after epoch 5500: 0.650155\n",
      "Cost after epoch 5600: 0.650153\n",
      "Cost after epoch 5700: 0.650152\n",
      "Cost after epoch 5800: 0.650151\n",
      "Cost after epoch 5900: 0.650150\n",
      "Cost after epoch 6000: 0.650149\n",
      "Cost after epoch 6100: 0.650147\n",
      "Cost after epoch 6200: 0.650146\n",
      "Cost after epoch 6300: 0.650145\n",
      "Cost after epoch 6400: 0.650144\n",
      "Cost after epoch 6500: 0.650143\n",
      "Cost after epoch 6600: 0.650142\n",
      "Cost after epoch 6700: 0.650140\n",
      "Cost after epoch 6800: 0.650139\n",
      "Cost after epoch 6900: 0.650138\n",
      "Cost after epoch 7000: 0.650136\n",
      "Cost after epoch 7100: 0.650135\n",
      "Cost after epoch 7200: 0.650135\n",
      "Cost after epoch 7300: 0.650134\n",
      "Cost after epoch 7400: 0.650133\n",
      "Cost after epoch 7500: 0.650131\n",
      "Cost after epoch 7600: 0.650129\n",
      "Cost after epoch 7700: 0.650129\n",
      "Cost after epoch 7800: 0.650128\n",
      "Cost after epoch 7900: 0.650126\n",
      "Cost after epoch 8000: 0.650125\n",
      "Cost after epoch 8100: 0.650124\n",
      "Cost after epoch 8200: 0.650123\n",
      "Cost after epoch 8300: 0.650122\n",
      "Cost after epoch 8400: 0.650122\n",
      "Cost after epoch 8500: 0.650120\n",
      "Cost after epoch 8600: 0.650118\n",
      "Cost after epoch 8700: 0.650117\n",
      "Cost after epoch 8800: 0.650117\n",
      "Cost after epoch 8900: 0.650116\n",
      "Cost after epoch 9000: 0.650114\n",
      "Cost after epoch 9100: 0.650113\n",
      "Cost after epoch 9200: 0.650113\n",
      "Cost after epoch 9300: 0.650111\n",
      "Cost after epoch 9400: 0.650110\n",
      "Cost after epoch 9500: 0.650109\n",
      "Cost after epoch 9600: 0.650108\n",
      "Cost after epoch 9700: 0.650106\n",
      "Cost after epoch 9800: 0.650106\n",
      "Cost after epoch 9900: 0.650104\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20419ab9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.6075499\n",
      "Test Accuracy: 0.5996109\n",
      "Neural network training time consumed: 287.755611 secs\n"
     ]
    }
   ],
   "source": [
    "## training and predict\n",
    "tf.reset_default_graph()\n",
    "start_time = time.time()\n",
    "neural_num = [X_train.shape[0], 25, 12, 2]\n",
    "# cost function of mini_batch may not decrease at each iteration\n",
    "figname = r'D:\\wkspacePY\\STA 141C\\picture\\nn3_feature_10000'\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 10000, learning_rate = 1, figname = figname, period = 5000)\n",
    "end_time = time.time()\n",
    "print(\"Neural network training time consumed: %lf secs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.710124\n",
      "Cost after epoch 100: 0.664817\n",
      "Cost after epoch 200: 0.655584\n",
      "Cost after epoch 300: 0.653512\n",
      "Cost after epoch 400: 0.652876\n",
      "Cost after epoch 500: 0.652488\n",
      "Cost after epoch 600: 0.652115\n",
      "Cost after epoch 700: 0.651826\n",
      "Cost after epoch 800: 0.651643\n",
      "Cost after epoch 900: 0.651518\n",
      "Cost after epoch 1000: 0.651432\n",
      "Cost after epoch 1100: 0.651292\n",
      "Cost after epoch 1200: 0.651243\n",
      "Cost after epoch 1300: 0.651126\n",
      "Cost after epoch 1400: 0.651023\n",
      "Cost after epoch 1500: 0.650910\n",
      "Cost after epoch 1600: 0.651391\n",
      "Cost after epoch 1700: 0.650963\n",
      "Cost after epoch 1800: 0.651283\n",
      "Cost after epoch 1900: 0.650986\n",
      "Cost after epoch 2000: 0.651194\n",
      "Cost after epoch 2100: 0.650587\n",
      "Cost after epoch 2200: 0.650580\n",
      "Cost after epoch 2300: 0.650573\n",
      "Cost after epoch 2400: 0.650566\n",
      "Cost after epoch 2500: 0.650560\n",
      "Cost after epoch 2600: 0.650553\n",
      "Cost after epoch 2700: 0.650547\n",
      "Cost after epoch 2800: 0.650541\n",
      "Cost after epoch 2900: 0.650534\n",
      "Cost after epoch 3000: 0.650528\n",
      "Cost after epoch 3100: 0.650522\n",
      "Cost after epoch 3200: 0.650516\n",
      "Cost after epoch 3300: 0.650510\n",
      "Cost after epoch 3400: 0.650504\n",
      "Cost after epoch 3500: 0.650498\n",
      "Cost after epoch 3600: 0.650492\n",
      "Cost after epoch 3700: 0.650486\n",
      "Cost after epoch 3800: 0.650481\n",
      "Cost after epoch 3900: 0.650475\n",
      "Cost after epoch 4000: 0.650469\n",
      "Cost after epoch 4100: 0.650469\n",
      "Cost after epoch 4200: 0.650468\n",
      "Cost after epoch 4300: 0.650468\n",
      "Cost after epoch 4400: 0.650467\n",
      "Cost after epoch 4500: 0.650467\n",
      "Cost after epoch 4600: 0.650466\n",
      "Cost after epoch 4700: 0.650466\n",
      "Cost after epoch 4800: 0.650465\n",
      "Cost after epoch 4900: 0.650464\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2041ea918d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.6075499\n",
      "Test Accuracy: 0.6009079\n",
      "Neural network training time consumed: 218.302242 secs\n"
     ]
    }
   ],
   "source": [
    "## training and predict\n",
    "tf.reset_default_graph()\n",
    "start_time = time.time()\n",
    "neural_num = [X_train.shape[0], 32, 16, 8, 4, 2]\n",
    "# cost function of mini_batch may not decrease at each iteration\n",
    "# not work: parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 1500, learning_rate = 10**(-1))\n",
    "figname = r'D:\\wkspacePY\\STA 141C\\picture\\nn5_feature_5000'\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 5000, learning_rate = 1,figname = figname)\n",
    "end_time = time.time()\n",
    "print(\"Neural network training time consumed: %lf secs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.693387\n",
      "Cost after epoch 100: 0.687279\n",
      "Cost after epoch 200: 0.687304\n",
      "Cost after epoch 300: 0.687303\n",
      "Cost after epoch 400: 0.687303\n",
      "Cost after epoch 500: 0.687303\n",
      "Cost after epoch 600: 0.687303\n",
      "Cost after epoch 700: 0.687303\n",
      "Cost after epoch 800: 0.687303\n",
      "Cost after epoch 900: 0.687303\n",
      "Cost after epoch 1000: 0.687303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-d9adccacbee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# not work: parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 1500, learning_rate = 10**(-1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfigname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'D:\\wkspacePY\\STA 141C\\picture\\nn10_5000'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneural_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Neural network training time consumed: %lf secs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-149201926ea6>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, nn, learning_rate, num_epochs, print_cost, figname, period)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtmp_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mepoch_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## training and predict\n",
    "tf.reset_default_graph()\n",
    "start_time = time.time()\n",
    "neural_num = [X_train.shape[0], 14, 12, 10, 8, 20, 18, 16, 6, 4, 2]\n",
    "# cost function of mini_batch may not decrease at each iteration\n",
    "# not work: parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 1500, learning_rate = 10**(-1))\n",
    "figname = r'D:\\wkspacePY\\STA 141C\\picture\\nn10_5000'\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, neural_num, num_epochs = 5000, learning_rate = 0.01, figname = figname, period = 5000)\n",
    "end_time = time.time()\n",
    "print(\"Neural network training time consumed: %lf secs\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
